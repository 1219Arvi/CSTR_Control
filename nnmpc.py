# -*- coding: utf-8 -*-
"""NNMPC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kCFfiqlEOls6zHGEccgzJvDhV92PLMD3
"""

# Set the environment variable again
import os


import tensorflow as tf # Import tensorflow explicitly
from tensorflow import keras
from keras import Sequential,Input,Model
from keras.layers import Dense , Dropout
from keras.initializers import HeNormal
from keras.regularizers import l2
from keras.callbacks import EarlyStopping
print("TensorFlow version:", tf.__version__)
print("Keras (tf_keras) version:", keras.__version__)

# Continue with the rest of your imports and code from here
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib
import matplotlib.pyplot as plt

from google.colab import files

# Rest of your code...

import tensorflow
tensorflow.__version__

!pip install tf2onnx
!pip install onnx

import tf2onnx
import onnx

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib
import matplotlib.pyplot as plt

from google.colab import files

dataset = files.upload()

df=pd.read_csv("NNMPC_dataset.csv" ,header=None)

df.columns=[ "q(t-4)", "q(t-3)", "q(t-2)", "q(t-1)", "q(t)", "qc(t-4)", "qc(t-3)", "qc(t-2)", "qc(t-1)", "qc(t)","T(t-4)", "T(t-3)", "T(t-2)", "T(t-1)", "T(t)"  , "T(t+1)"]

print(df.head())

feature_cols = df.columns[:15]
target_cols = df.columns[15:]

X_df = df[feature_cols]
Y_df = df[target_cols]

print(Y_df.head())

y_min = Y_df.min().to_numpy()
y_max = Y_df.max().to_numpy()
x_min = X_df.min().to_numpy()
x_max = X_df.max().to_numpy()
print("y_min =", y_min)
print("y_max =", y_max)
print("x_min =", x_min)
print("x_max =", x_max)

from scipy.io import savemat
savemat('y_min_max.mat', {'y_min': y_min, 'y_max': y_max})
savemat("x_min_max.mat",{"x_max":x_max,'x_min':x_min})

X_scaler=MinMaxScaler()
Y_scaler=MinMaxScaler()

X_scaled = pd.DataFrame(X_scaler.fit_transform(X_df), columns=feature_cols)
Y_scaled = pd.DataFrame(Y_scaler.fit_transform(Y_df), columns=target_cols)

joblib.dump(X_scaler, 'X_scaler.pkl')

print(Y_scaled.head())

X_train, X_temp, Y_train, Y_temp = train_test_split(X_scaled, Y_scaled, test_size=0.3, random_state=42)

X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)

# model = Sequential()
# model.add(Dense(10, activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-2), input_shape=(20,)))
# model.add(Dropout(0.3))
# model.add(Dense(5, activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-2)))
# model.add(Dropout(0.2))
# model.add(Dense(2, activation='linear'))  # Output layer

from keras.layers import Input, Dense, Dropout
from keras.models import Model
from keras.initializers import HeNormal
from keras.regularizers import l2

# Define input
inputs = Input(shape=(15,), name="input")

# First dense layer + dropout
x = Dense(8, activation='leaky_relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-2))(inputs)
x = Dropout(0.3)(x)

# Second dense layer + dropout
x = Dense(4, activation='leaky_relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-2))(x)
x = Dropout(0.2)(x)

# Output layer
outputs = Dense(1, activation='linear', name="output")(x)

# Create model
model = Model(inputs=inputs, outputs=outputs)

model.summary()

model.compile(optimizer='adam',
              loss='mean_squared_error', metrics=["mean_absolute_error" ] )

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True,
    verbose=1
)

history = model.fit(
    X_train, Y_train,
    validation_data=(X_val, Y_val),
    epochs=100,
    batch_size=32,
    callbacks=[early_stop],
    verbose=1
)

def plot_training_history(history):
    metrics = history.history.keys()
    plt.figure(figsize=(14, 10))

    plt.subplot(2, 2, 1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('MSE Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()


    plt.subplot(2, 2, 2)
    plt.plot(history.history['mean_absolute_error'], label='Train MAE')
    plt.plot(history.history['val_mean_absolute_error'], label='Val MAE')
    plt.title('Mean Absolute Error')
    plt.xlabel('Epochs')
    plt.ylabel('MAE')
    plt.legend()



    plt.tight_layout()
    plt.show()

plot_training_history(history)

results = model.evaluate(X_test, Y_test, verbose=1)

Y_pred_scaled= model.predict(X_test)
Y_pred = Y_scaler.inverse_transform(Y_pred_scaled)
Y_true = Y_scaler.inverse_transform(Y_test)

def plot_predictions(Y_true, Y_pred):
    n_outputs = Y_true.shape[1]
    labels = ['T_A (t+1)', 'T (t+1)']

    plt.figure(figsize=(12, 5))

    for i in range(n_outputs):
        plt.subplot(1, n_outputs, i+1)
        plt.scatter(Y_true[:, i], Y_pred[:, i], alpha=0.6, edgecolors='k')
        plt.plot([Y_true[:, i].min(), Y_true[:, i].max()],
                 [Y_true[:, i].min(), Y_true[:, i].max()],
                 'r--', label='Ideal')
        plt.xlabel('Actual ' + labels[i])
        plt.ylabel('Predicted ' + labels[i])
        plt.title(f'Prediction vs Actual: {labels[i]}')
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.show()

plot_predictions(Y_true, Y_pred)

print("TensorFlow version:", tf.__version__)
print("Keras (tf_keras) version:", keras.__version__)

!zip -r mymodel.zip mymodel
files.download("mymodel.zip")

spec = (tf.TensorSpec([1, 15], tf.float32, name="x"),)

onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)
onnx.save(onnx_model, "NewM.onnx")

spec = (tf.TensorSpec((None, 20), tf.float32, name="input"),)
output_path = "my_model.onnx"

# (Optionally call the model once to build it)
model(tf.random.uniform([1, 20]))

# Convert
model_proto, _ = tf2onnx.convert.from_keras(
    model,
    input_signature=spec,
    opset=13,
    output_path=output_path
)

print(f"Model saved to {output_path}")