# -*- coding: utf-8 -*-
"""NNMPC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kCFfiqlEOls6zHGEccgzJvDhV92PLMD3
"""

!pip install tensorflow

from tensorflow import keras
from keras import Sequential
from keras.layers import Dense , Dropout
from keras.initializers import HeNormal
from keras.regularizers import l2
from keras.callbacks import EarlyStopping

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib
import matplotlib.pyplot as plt

from google.colab import files

dataset = files.upload()

df=pd.read_csv("NNMPC_dataset.csv" ,header=None)

df.columns=[ "q(t-4)", "q(t-3)", "q(t-2)", "q(t-1)", "q(t)", "qc(t-4)", "qc(t-3)", "qc(t-2)", "qc(t-1)", "qc(t)", "CA(t-4)", "CA(t-3)", "CA(t-2)", "CA(t-1)", "CA(t)", "T(t-4)", "T(t-3)", "T(t-2)", "T(t-1)", "T(t)" ,"C(t+1)" , "T(t+1)"]

print(df.head())

feature_cols = df.columns[:20]
target_cols = df.columns[20:]

X_df = df[feature_cols]
Y_df = df[target_cols]

print(X_df.head())

X_scaler=MinMaxScaler()
Y_scaler=MinMaxScaler()

X_scaled = pd.DataFrame(X_scaler.fit_transform(X_df), columns=feature_cols)
Y_scaled = pd.DataFrame(Y_scaler.fit_transform(Y_df), columns=target_cols)

joblib.dump(X_scaler, 'X_scaler.pkl')
joblib.dump(Y_scaler, 'Y_scaler.pkl')

print(Y_scaled.head())

X_train, X_temp, Y_train, Y_temp = train_test_split(X_scaled, Y_scaled, test_size=0.3, random_state=42)

X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)

he_init = HeNormal()
reg = l2(1e-2)

model = Sequential([
    Dense(10, activation='relu', kernel_initializer=he_init, kernel_regularizer=reg, input_shape=(20,)),
    Dropout(0.3),

    Dense(5, activation='relu', kernel_initializer=he_init, kernel_regularizer=reg),
    Dropout(0.2),

    Dense(2, activation='relu')])

model.compile(optimizer='adam',
              loss='mean_squared_error', metrics=["mean_absolute_error" ] )

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True,
    verbose=1
)

history = model.fit(
    X_train, Y_train,
    validation_data=(X_val, Y_val),
    epochs=100,
    batch_size=32,
    callbacks=[early_stop],
    verbose=1
)

def plot_training_history(history):
    metrics = history.history.keys()
    plt.figure(figsize=(14, 10))

    plt.subplot(2, 2, 1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('MSE Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()


    plt.subplot(2, 2, 2)
    plt.plot(history.history['mean_absolute_error'], label='Train MAE')
    plt.plot(history.history['val_mean_absolute_error'], label='Val MAE')
    plt.title('Mean Absolute Error')
    plt.xlabel('Epochs')
    plt.ylabel('MAE')
    plt.legend()



    plt.tight_layout()
    plt.show()

plot_training_history(history)

results = model.evaluate(X_test, Y_test, verbose=1)

Y_pred_scaled = model.predict(X_test)

Y_pred = Y_scaler.inverse_transform(Y_pred_scaled)
Y_true = Y_scaler.inverse_transform(Y_test)

def plot_predictions(Y_true, Y_pred):
    n_outputs = Y_true.shape[1]
    labels = ['C_A (t+1)', 'T (t+1)']

    plt.figure(figsize=(12, 5))

    for i in range(n_outputs):
        plt.subplot(1, n_outputs, i+1)
        plt.scatter(Y_true[:, i], Y_pred[:, i], alpha=0.6, edgecolors='k')
        plt.plot([Y_true[:, i].min(), Y_true[:, i].max()],
                 [Y_true[:, i].min(), Y_true[:, i].max()],
                 'r--', label='Ideal')
        plt.xlabel('Actual ' + labels[i])
        plt.ylabel('Predicted ' + labels[i])
        plt.title(f'Prediction vs Actual: {labels[i]}')
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.show()

plot_predictions(Y_true, Y_pred)